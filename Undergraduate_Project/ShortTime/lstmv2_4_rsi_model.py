# -*- coding: utf-8 -*-
"""LSTMv2_only_price_m_pred_btc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OM6ZNCxUhbqCtdVSAoFoV7N8y-RUAHfr
"""

from numpy import array
from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dense
from keras.layers import Flatten
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import glob

!git clone https://github.com/binance/binance-public-data.git

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/binance-public-data/python

!python3 download-kline.py -s BTCUSDT  -i 4h -startDate 2021-01-01



def form(yhat,y,mode,ix=3):
    tp=[0]
    tn=[0]
    fn=[0]
    fp=[0]
    yuzdelik=[[0],[0],[0],[0]]
    if mode==1:
        for index,i in enumerate(yhat):
            result=i[ix]-y[index-1,ix]
            if index==0:
                continue
            if y[index-1,ix]>y[index,ix]:#dusmus
                if result>0: 
                    fn.append(abs(i[ix]-y[index,ix]))#negatif
                    yuzdelik[2].append((y[index,ix]/y[index-1,ix]+0.001)-1)
                else:
                    tn.append(abs(i[ix]-y[index,ix]))
                    yuzdelik[3].append((y[index,ix]/y[index-1,ix]+0.001)-1)
            else:  #artmis
                if result>0: 
                    tp.append(abs(i[ix]-y[index,ix]))#negatif
                    yuzdelik[0].append((y[index,ix]/y[index-1,ix]+0.001)-1)
                else:
                    fp.append(abs(i[ix]-y[index,ix]))
                    yuzdelik[1].append((y[index,ix]/y[index-1,ix]+0.001)-1)
    elif mode==0:
        count_t=0
        count_g=0
        count_l=0
        count_w=[0]
        count_ls=[0]
        count_tr=[0]
        price_pred=[0]
        price_per=[0]
        for index,i in enumerate(yhat):
            result=i-y[index-1]
            if index==0:
                continue
            if y[index-1]>y[index]:#dusmus
                if result>0: 
                    fn.append(abs(i-y[index]))#negatif
                    yuzdelik[2].append((y[index]/y[index-1]+0.001)-1)
                    price_per.append((y[index]/y[index-1]+0.001)-1)
                    count_ls.append(count_l)
                    count_tr.append(count_t)
                    price_pred.append(0)
                    count_l=0
                    count_t=0
                else:
                    tn.append(abs(i-y[index]))
                    yuzdelik[3].append((y[index]/y[index-1]+0.001)-1)
                    price_per.append((y[index]/y[index-1]+0.001)-1)
                    count_l+=1
                    count_t+=1
                    price_pred.append(1)
            else:  #artmis
                if result>0: 
                    tp.append(abs(i-y[index]))#pozitif
                    yuzdelik[0].append((y[index]/y[index-1]+0.001)-1)
                    price_per.append((y[index]/y[index-1]+0.001)-1)
                    count_g+=1
                    count_t+=1    
                    price_pred.append(1)

                else:
                    fp.append(abs(i-y[index]))
                    yuzdelik[1].append((y[index]/y[index-1]+0.001)-1)
                    price_per.append((y[index]/y[index-1]+0.001)-1)
                    count_w.append(count_g)
                    count_tr.append(count_t)
                    count_g=0
                    count_t=0
                    price_pred.append(0)
        
    print()
    print('Mean')
    print([np.mean(tp),"%{}".format(np.mean(yuzdelik[0])*100),"||||",np.mean(fp),"%{}".format(np.mean(yuzdelik[1])*100)])
    print([np.mean(fn),"-%{}".format(np.mean(np.abs(yuzdelik[2])*100)),"||||",np.mean(tn),"-%{}".format(np.mean(np.abs(yuzdelik[3]))*100)])
    print()
    print('Count')
    print([len(tp)-1,len(fp)-1])
    print([len(fn)-1,len(tn)-1])
    print("acc %{}".format((len(tp)+len(tn)-2)/(len(tp)+len(fp)+len(fn)+len(tn)-4)))
    print()
    print('Max')
    print([np.max(tp),"%{}".format(np.max(yuzdelik[0])*100),"||||",np.max(fp),"%{}".format(np.max(yuzdelik[1])*100)])
    print([np.max(fn),"-%{}".format(np.max(np.abs(yuzdelik[2])*100)),"||||",np.max(tn),"-%{}".format(np.max(np.abs(yuzdelik[3]))*100)])
    print()
    print('Min')
    print([np.min(tp),"%{}".format(np.min(np.abs(yuzdelik[0]))*100),"||||",np.min(fp),"%{}".format(np.min(np.abs(yuzdelik[1]))*100)])
    print([np.min(fn),"-%{}".format(np.min(np.abs(yuzdelik[2]))*100),"||||",np.min(tn),"-%{}".format(np.min(np.abs(yuzdelik[3]))*100)])
    print()
    print("Means")
    print(np.mean(count_w),np.mean(count_ls),np.mean(count_tr))
    print()
    print("Maxs")
    print(np.max(count_w),np.max(count_ls),np.max(count_tr))
    money=100
    for i in range(len(price_per)):
        if price_pred[i]==1:
          #print("+++money was",money," and rate is",price_per[i])
          money+=money*abs(price_per[i])
          #print("money become ",money)
        else:
          # print("---money was",money," and rate is",price_per[i])
          money-=money*abs(price_per[i])
          # print("money become ",money," and ",i)
    return count_tr,price_pred,price_per,money

# split a multivariate sequence into samples
def split_sequences(sequences, n_steps):
    X, y = list(), list()

    for i in range(len(sequences)):
        # find the end of this pattern
        end_ix = i + n_steps
        # check if we are beyond the dataset
        if end_ix > len(sequences):
            break
        # gather input and output parts of the pattern
        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]
        X.append(seq_x)
        y.append(seq_y)
    
    return array(X), array(y)

def calc_rsi(dataset,rsi_ohlc=3,mode=0):
  dataset = pd.DataFrame(dataset,columns=["Open","High","Low","Close"])
  coin_rsi=dataset.copy()
  data=coin_rsi.copy()
  a=coin_rsi.columns[rsi_ohlc]
  coin_rsi.drop(coin_rsi.columns.difference([a]), 1, inplace=True)
  coin_rsi=coin_rsi.reset_index(drop=True,inplace=False)
  coin_rsi["diff"]=coin_rsi.diff(1)

  coin_rsi['gain'] = coin_rsi['diff'].clip(lower=0).round(2)
  coin_rsi['loss'] = coin_rsi['diff'].clip(upper=0).abs().round(2)
  coin_rsi

  window_length=14
  # Get initial Averages
  coin_rsi['avg_gain'] = coin_rsi['gain'].rolling(window=window_length, min_periods=window_length).mean()[:window_length+1]
  coin_rsi['avg_loss'] = coin_rsi['loss'].rolling(window=window_length, min_periods=window_length).mean()[:window_length+1]
  # View Result

  # View first SMA value

  for i, row in enumerate(coin_rsi['avg_gain'].iloc[window_length+1:]):
      coin_rsi['avg_gain'].iloc[i + window_length + 1] =\
          (coin_rsi['avg_gain'].iloc[i + window_length] *
          (window_length - 1) +
          coin_rsi['gain'].iloc[i + window_length + 1])\
          / window_length
  # Average Losses
  for i, row in enumerate(coin_rsi['avg_loss'].iloc[window_length+1:]):
      coin_rsi['avg_loss'].iloc[i + window_length + 1] =\
          (coin_rsi['avg_loss'].iloc[i + window_length] *
          (window_length - 1) +
          coin_rsi['loss'].iloc[i + window_length + 1])\
          / window_length
  # View initial results

  coin_rsi['rs'] = coin_rsi['avg_gain'] / coin_rsi['avg_loss']
  coin_rsi['rsi'] = 100 - (100 / (1.0 + coin_rsi['rs']))

  # View Result
  if mode==1:
    return np.array(coin_rsi["rsi"])[-1]
  return coin_rsi["rsi"]

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/binance-public-data/python/data/spot/monthly/klines/BTCUSDT/4h
path = os.getcwd()
csv_files = glob.glob(os.path.join(path, "*.zip"))
li=[]
for f in csv_files:
      
    # read the csv file
    df = pd.read_csv(f, header=None)
    li.append(df)
    # print the location and filename
    print('Location:', f)
    print('File Name:', f.split("\\")[-1])
      
    # print the content
    print('Content:')
    display(df)
    print()
frame = pd.concat(li, ignore_index=True)
dataset_c=frame.copy()
dataset_c.columns
dataset_c.rename(columns={0:'Open time',1: 'Open',2: 'High',3: 'Low',4: 'Close',5: 'Volume',6: 'Close time	',7: 'Quote asset volume	',8: 'Number of trades	',9: 'Taker buy base asset volume',10: 'Taker buy quote asset volume',11: 'Ignore'}, inplace=True)
print(dataset_c.columns)
# %cd /content/binance-public-data/python/data/spot/daily/klines/BTCUSDT/4h
path = os.getcwd()
csv_files = glob.glob(os.path.join(path, "*.zip"))
li=[]
for f in csv_files:
      
    # read the csv file
    df = pd.read_csv(f, header=None)
    li.append(df)
    # print the location and filename
    print('Location:', f)
    print('File Name:', f.split("\\")[-1])
      
    # print the content
    print('Content:')
    display(df)
    print()
frame = pd.concat(li, ignore_index=True)
dataset_d=frame.copy()
dataset_d.columns
dataset_d.rename(columns={0:'Open time',1: 'Open',2: 'High',3: 'Low',4: 'Close',5: 'Volume',6: 'Close time	',7: 'Quote asset volume	',8: 'Number of trades	',9: 'Taker buy base asset volume',10: 'Taker buy quote asset volume',11: 'Ignore'}, inplace=True)
dataset_p=pd.concat([dataset_c,dataset_d])
dataset_p["Open time"].sort_values()

dataset_p.astype(str)

dataset_p=dataset_p.drop_duplicates()

dataset_p=dataset_p.astype(float)

dataset_p=dataset_p.sort_values(by=['Open time'])

dataset_c=dataset_p
dataset_c['Open time'] = pd.to_datetime(dataset_c['Open time'], unit='ms')

dataset_c.index=dataset_c['Open time']

dataset_c=dataset_c[["Open","High","Low","Close"]]

dataset_c

coin_rsi_o=calc_rsi(dataset_c,0)
coin_rsi_h=calc_rsi(dataset_c,1)
coin_rsi_l=calc_rsi(dataset_c,2)
coin_rsi_c=calc_rsi(dataset_c,3)
dataset_t=dataset_c.copy()
dataset_t

dataset_t["rsi_o"]=coin_rsi_o.values
dataset_t["rsi_h"]=coin_rsi_h.values
dataset_t["rsi_l"]=coin_rsi_l.values
dataset_t["rsi_c"]=coin_rsi_c.values

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/
dataset_t.to_csv('out.csv', index=False)

dataset_t=pd.read_csv("out.zip")

dataset_train_c=dataset_t[["rsi_o","rsi_h","rsi_l","Open","High","Low","Close"]]
dataset_train_l=dataset_t[["rsi_o","rsi_h","rsi_c",'Open','High','Close','Low']]
dataset_train_h=dataset_t[["rsi_o","rsi_l","rsi_c",'Open','Low','Close','High']]
dataset_train_o=dataset_t[["rsi_h","rsi_l","rsi_c",'High','Low','Close','Open']]

dataset_train_c

dataset_train_c=dataset_train_c.dropna()



dataset_train_l=dataset_train_l.dropna()



dataset_train_h=dataset_train_h.dropna()



dataset_train_o=dataset_train_o.dropna()

dataset_train_c=dataset_train_c.reset_index(drop=True)
dataset_train_l=dataset_train_l.reset_index(drop=True)
dataset_train_h=dataset_train_h.reset_index(drop=True)
dataset_train_o=dataset_train_o.reset_index(drop=True)

# choose a number of time steps
n_steps =3


# convert into input/output
pre_dataset_c=dataset_train_c.values.copy()
num=int(len(pre_dataset_c)*20/100)
pre_dataset_c.astype(float)
print(pre_dataset_c.shape)
X_c, y_c = split_sequences(pre_dataset_c[:,:], n_steps)
X_valid_c, y_valid_c = split_sequences(pre_dataset_c[-num:-int(num/2),:], n_steps)
X_test_c,y_test_c =split_sequences(pre_dataset_c[-int(num/2):-int(num/4),:], n_steps)
son_yuz_c,sonyuz_c=split_sequences(pre_dataset_c[-int(num/4):,:], n_steps)
n_features=X_c.shape[2]
# define model
model_c = Sequential()
model_c.add(LSTM(units=50, input_shape=(n_steps, n_features), activation='relu'))
model_c.add(Dense(units=1))
model_c.compile(optimizer='adam', loss='mse', run_eagerly=True)
# choose a number of time steps


# # convert into input/output
pre_dataset_l=dataset_train_l.values.copy()

pre_dataset_l.astype(float)
print(pre_dataset_l.shape)
X_l, y_l = split_sequences(pre_dataset_l[0:,:], n_steps)
X_valid_l, y_valid_l = split_sequences(pre_dataset_l[-num:-int(num/2),:], n_steps)
X_test_l,y_test_l =split_sequences(pre_dataset_l[-int(num/2):-int(num/4),:], n_steps)
son_yuz_l,sonyuz_l=split_sequences(pre_dataset_l[-int(num/4):,:], n_steps)
print(X_l.shape,X_valid_l.shape,X_test_l.shape,son_yuz_l.shape)
# # define model
model_l = Sequential()
model_l.add(LSTM(units=50, input_shape=(n_steps, n_features), activation='relu'))
model_l.add(Dense(units=1))
model_l.compile(optimizer='adam', loss='mse', run_eagerly=True)

# # convert into input/output

pre_dataset_h=dataset_train_h.values.copy()

pre_dataset_h.astype(float)
print(pre_dataset_h.shape)
X_h, y_h = split_sequences(pre_dataset_h[:,:], n_steps)
X_valid_h, y_valid_h = split_sequences(pre_dataset_h[-num:-int(num/2),:], n_steps)
X_test_h,y_test_h =split_sequences(pre_dataset_h[-int(num/2):-int(num/4),:], n_steps)
son_yuz_h,sonyuz_h=split_sequences(pre_dataset_h[-int(num/4):,:], n_steps)

model_h = Sequential()
model_h.add(LSTM(units=50, input_shape=(n_steps, n_features), activation='relu'))
model_h.add(Dense(units=1))
model_h.compile(optimizer='adam', loss='mse', run_eagerly=True)



pre_dataset_o=dataset_train_o.values.copy()

pre_dataset_o.astype(float)

X_o, y_o = split_sequences(pre_dataset_o[:,:], n_steps)
X_valid_o, y_valid_o = split_sequences(pre_dataset_o[-num:-int(num/2),:], n_steps)
X_test_o,y_test_o =split_sequences(pre_dataset_o[-int(num/2):-int(num/4),:], n_steps)
son_yuz_o,sonyuz_o=split_sequences(pre_dataset_o[-int(num/4):,:], n_steps)
n_features = X_o.shape[2]
# define model
model_o = Sequential()
model_o.add(LSTM(units=50, input_shape=(n_steps, n_features), activation='relu'))
model_o.add(Dense(units=1))   
model_o.compile(optimizer='adam', loss='mse', run_eagerly=True)

# fit model
print(X_c.shape,y_c.shape)
history_c=model_c.fit(X_c, y_c,validation_data=(X_valid_c,y_valid_c), epochs=10)
history_l=model_l.fit(X_l, y_l,validation_data=(X_valid_l,y_valid_l), epochs=10)
history_h=model_h.fit(X_h, y_h,validation_data=(X_valid_h,y_valid_h), epochs=10)
history_o=model_o.fit(X_o, y_o,validation_data=(X_valid_o,y_valid_o), epochs=10)

yhat_c = model_c.predict(X_c)
yhat_valid_c = model_c.predict(X_valid_c)
yhat_test_c=model_c.predict(X_test_c)

yhat_l = model_l.predict(X_l)
yhat_valid_l = model_l.predict(X_valid_l)
yhat_test_l=model_l.predict(X_test_l)

yhat_h = model_h.predict(X_h)
yhat_valid_h = model_h.predict(X_valid_h)
yhat_test_h=model_h.predict(X_test_h)

yhat_o = model_o.predict(X_o)
yhat_valid_o = model_o.predict(X_valid_o)
yhat_test_o=model_o.predict(X_test_o)

# yhat_sonyuz=model_o.predict(son_yuz_o[-1])

yhat_sonyuz_c=model_c.predict(son_yuz_c[-1].reshape(1,n_steps,6))
yhat_sonyuz_h=model_h.predict(son_yuz_h[-1].reshape(1,n_steps,6))
yhat_sonyuz_l=model_l.predict(son_yuz_l[-1].reshape(1,n_steps,6))
yhat_sonyuz_o=model_o.predict(son_yuz_o[-1].reshape(1,n_steps,6))
print(yhat_sonyuz_o,yhat_sonyuz_h,yhat_sonyuz_l,yhat_sonyuz_c)

from numpy.core.numeric import count_nonzero
count,price,pred,money=form(yhat_c[:],y_c,mode=0)
print("Start Money=100 End Money=",money,"Gain(%)=",(money-100))

"""Mean
[255.90721, '%3.500122612638581', '||||', 324.45013, '%1.5524074243927102']
[73.23644, '-%0.4442863835786388', '||||', 153.95036, '-%2.9751761036363686']

Count
[711, 207]
[72, 691]
acc %0.8340273646638905

Max
[5622.949, '%27.60232808946914', '||||', 2805.8906, '%16.397235496479134']
[754.4219, '-%4.33348270618088', '||||', 3091.039, '-%38.91332585458471']

Min
[0.056518555, '%0.10016216279395973', '||||', 1.2766113, '%0.10384627302648664']
[1.9434814, '-%0.0018391240065307457', '||||', 0.17218018, '-%0.0008789751984927818']
"""

fig, ax = plt.subplots()
ax.plot(yhat_c,color="b")
#ax.plot(n_pred,color="r")
ax.plot(y_c,color="r")
#ax.plot(nhat_pred,color="b")

fig, ax = plt.subplots()
ax.plot(yhat_valid_o[:],color="b")
#ax.plot(y_valid_o,color="r")
print(len(yhat_valid_o),len(y_valid_o))

count,pred,rate,money=form(yhat_valid_c[:],y_valid_c,mode=0)
print("Start Money=100 End Money=",money,"Gain(%)=",(money-100),"Daily gain=",(money-100)/180)

"""
Mean
[1031.178, '%3.331334037113545', '||||', 1286.772, '%1.7885532546138128']
[501.02475, '-%0.4716445902029835', '||||', 559.0855, '-%2.826466783358267']

Count
[72, 24]
[6, 82]
acc %0.8369565217391305

Max
[3086.961, '%10.007252108238273', '||||', 3668.293, '%5.588760761207312']
[870.14453, '-%0.9298480434231982', '||||', 2360.2812, '-%11.060657227970871']

Min
[4.9335938, '%0.1466816755341549', '||||', 153.99805, '%0.18166686597356207']
[235.58203, '-%0.04856934775727684', '||||', 4.423828, '-%0.009229282995093513']"""