{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perception Manuel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29.74551615,  7.60876611, 76.61461163],\n",
       "       [42.83314135, 86.67992275, 57.10149238],\n",
       "       [75.46903755, 19.43631034, 78.07358459],\n",
       "       [13.12758428, 42.84638928, 17.94776172],\n",
       "       [58.77574671, 53.24750893, 70.49688091]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.random.rand(300,3)\n",
    "X*=100\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29.74551615,  7.60876611, 76.61461163,  1.        ],\n",
       "       [42.83314135, 86.67992275, 57.10149238,  0.        ],\n",
       "       [75.46903755, 19.43631034, 78.07358459,  0.        ],\n",
       "       ...,\n",
       "       [ 9.75414356, 83.62788146, 36.04752574,  1.        ],\n",
       "       [ 5.69547236, 54.69273126, 99.4119588 ,  1.        ],\n",
       "       [64.09718533, 57.56363588, 32.91017406,  0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insant=[]\n",
    "for i in X:\n",
    "    insant.append([int(np.sum(i))%2])\n",
    "X=np.append(X,insant,axis=1)\n",
    "X[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, accuary: 0.4933333333333333\n",
      "Epoch: 1, accuary: 0.4866666666666667\n",
      "Epoch: 2, accuary: 0.49\n",
      "Epoch: 3, accuary: 0.4966666666666667\n",
      "Epoch: 4, accuary: 0.4933333333333333\n",
      "Epoch: 5, accuary: 0.4966666666666667\n",
      "Epoch: 6, accuary: 0.4666666666666667\n",
      "Epoch: 7, accuary: 0.4833333333333333\n",
      "Epoch: 8, accuary: 0.5166666666666666\n",
      "Epoch: 9, accuary: 0.48\n",
      "Epoch: 10, accuary: 0.45666666666666667\n",
      "Epoch: 11, accuary: 0.4866666666666667\n",
      "Epoch: 12, accuary: 0.4633333333333334\n",
      "Epoch: 13, accuary: 0.4933333333333333\n",
      "Epoch: 14, accuary: 0.4933333333333333\n",
      "Epoch: 15, accuary: 0.5\n",
      "Epoch: 16, accuary: 0.45666666666666667\n",
      "Epoch: 17, accuary: 0.48\n",
      "Epoch: 18, accuary: 0.5\n",
      "Epoch: 19, accuary: 0.4866666666666667\n",
      "Epoch: 20, accuary: 0.4933333333333333\n",
      "Epoch: 21, accuary: 0.4933333333333333\n",
      "Epoch: 22, accuary: 0.4966666666666667\n",
      "Epoch: 23, accuary: 0.4933333333333333\n",
      "Epoch: 24, accuary: 0.5133333333333333\n",
      "Epoch: 25, accuary: 0.4866666666666667\n",
      "Epoch: 26, accuary: 0.5066666666666666\n",
      "Epoch: 27, accuary: 0.51\n",
      "Epoch: 28, accuary: 0.47\n",
      "Epoch: 29, accuary: 0.5133333333333333\n",
      "Epoch: 30, accuary: 0.5\n",
      "Epoch: 31, accuary: 0.4866666666666667\n",
      "Epoch: 32, accuary: 0.4933333333333333\n",
      "Epoch: 33, accuary: 0.52\n",
      "Epoch: 34, accuary: 0.48\n",
      "Epoch: 35, accuary: 0.5\n",
      "Epoch: 36, accuary: 0.49\n",
      "Epoch: 37, accuary: 0.5033333333333334\n",
      "Epoch: 38, accuary: 0.51\n",
      "Epoch: 39, accuary: 0.4733333333333334\n",
      "Epoch: 40, accuary: 0.4866666666666667\n",
      "Epoch: 41, accuary: 0.4933333333333333\n",
      "Epoch: 42, accuary: 0.4766666666666667\n",
      "Epoch: 43, accuary: 0.5\n",
      "Epoch: 44, accuary: 0.4933333333333333\n",
      "Epoch: 45, accuary: 0.52\n",
      "Epoch: 46, accuary: 0.48\n",
      "Epoch: 47, accuary: 0.48\n",
      "Epoch: 48, accuary: 0.4666666666666667\n",
      "Epoch: 49, accuary: 0.53\n",
      "Epoch: 50, accuary: 0.5066666666666666\n",
      "Epoch: 51, accuary: 0.4866666666666667\n",
      "Epoch: 52, accuary: 0.4766666666666667\n",
      "Epoch: 53, accuary: 0.5233333333333333\n",
      "Epoch: 54, accuary: 0.49\n",
      "Epoch: 55, accuary: 0.4966666666666667\n",
      "Epoch: 56, accuary: 0.51\n",
      "Epoch: 57, accuary: 0.47\n",
      "Epoch: 58, accuary: 0.4866666666666667\n",
      "Epoch: 59, accuary: 0.51\n",
      "Epoch: 60, accuary: 0.4933333333333333\n",
      "Epoch: 61, accuary: 0.49\n",
      "Epoch: 62, accuary: 0.4933333333333333\n",
      "Epoch: 63, accuary: 0.4933333333333333\n",
      "Epoch: 64, accuary: 0.52\n",
      "Epoch: 65, accuary: 0.5133333333333333\n",
      "Epoch: 66, accuary: 0.49\n",
      "Epoch: 67, accuary: 0.4966666666666667\n",
      "Epoch: 68, accuary: 0.51\n",
      "Epoch: 69, accuary: 0.5133333333333333\n",
      "Epoch: 70, accuary: 0.4966666666666667\n",
      "Epoch: 71, accuary: 0.45333333333333337\n",
      "Epoch: 72, accuary: 0.4833333333333333\n",
      "Epoch: 73, accuary: 0.4666666666666667\n",
      "Epoch: 74, accuary: 0.45999999999999996\n",
      "Epoch: 75, accuary: 0.49\n",
      "Epoch: 76, accuary: 0.4866666666666667\n",
      "Epoch: 77, accuary: 0.5\n",
      "Epoch: 78, accuary: 0.5033333333333334\n",
      "Epoch: 79, accuary: 0.5\n",
      "Epoch: 80, accuary: 0.4833333333333333\n",
      "Epoch: 81, accuary: 0.4933333333333333\n",
      "Epoch: 82, accuary: 0.5066666666666666\n",
      "Epoch: 83, accuary: 0.45999999999999996\n",
      "Epoch: 84, accuary: 0.5\n",
      "Epoch: 85, accuary: 0.4966666666666667\n",
      "Epoch: 86, accuary: 0.5033333333333334\n",
      "Epoch: 87, accuary: 0.5166666666666666\n",
      "Epoch: 88, accuary: 0.4733333333333334\n",
      "Epoch: 89, accuary: 0.4866666666666667\n",
      "Epoch: 90, accuary: 0.51\n",
      "Epoch: 91, accuary: 0.5\n",
      "Epoch: 92, accuary: 0.4666666666666667\n",
      "Epoch: 93, accuary: 0.4866666666666667\n",
      "Epoch: 94, accuary: 0.4933333333333333\n",
      "Epoch: 95, accuary: 0.48\n",
      "Epoch: 96, accuary: 0.5033333333333334\n",
      "Epoch: 97, accuary: 0.49\n",
      "Epoch: 98, accuary: 0.5\n",
      "Epoch: 99, accuary: 0.4866666666666667\n"
     ]
    }
   ],
   "source": [
    "def activation(Row, Weights):\n",
    "    return 1.0 if np.sum(Row.T*Weights)>=0 else 0.0\n",
    "    \n",
    "    \n",
    "def train(Epoch,LearningRate,Sets):\n",
    "    X_size=int(len(Sets[0]))\n",
    "    Y_size=int(len(Sets))\n",
    "    weights=[0 for i in range(X_size-1)]#np.zeros\n",
    "    i=0\n",
    "    while i<Epoch:\n",
    "        error_count=0\n",
    "        for elements in Sets:\n",
    "            prediction=activation(elements[:X_size-1],weights)\n",
    "            is_error=elements[-1]-prediction\n",
    "            error_count+=abs(is_error)\n",
    "            j=0\n",
    "            while j<X_size-1:\n",
    "                weights[j]=weights[j]+LearningRate*is_error*elements[j]\n",
    "                j+=1\n",
    "        print(\"Epoch: {}, accuary: {}\".format(i,1-(error_count/Y_size)))\n",
    "        i+=1\n",
    "    return weights\n",
    "\n",
    "weights=train(100,0.01,X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_X=np.array([50.85356876,  6.02557976, 31.07784483])\n",
    "activation(predict_X,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=3, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 6.4705 - accuracy: 0.4469\n",
      "Epoch 2/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 3.4227 - accuracy: 0.5075\n",
      "Epoch 3/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.6965 - accuracy: 0.5286\n",
      "Epoch 4/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.0519 - accuracy: 0.4969\n",
      "Epoch 5/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7425 - accuracy: 0.5487\n",
      "Epoch 6/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7721 - accuracy: 0.5646\n",
      "Epoch 7/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7657 - accuracy: 0.5546\n",
      "Epoch 8/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8043 - accuracy: 0.5230\n",
      "Epoch 9/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7014 - accuracy: 0.5890\n",
      "Epoch 10/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.8032 - accuracy: 0.5114\n",
      "Epoch 11/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7605 - accuracy: 0.5311\n",
      "Epoch 12/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.7576 - accuracy: 0.5469\n",
      "Epoch 13/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7464 - accuracy: 0.5770\n",
      "Epoch 14/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7561 - accuracy: 0.5476\n",
      "Epoch 15/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7442 - accuracy: 0.6002\n",
      "Epoch 16/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7069 - accuracy: 0.5542\n",
      "Epoch 17/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.5764\n",
      "Epoch 18/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7551 - accuracy: 0.5366\n",
      "Epoch 19/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7014 - accuracy: 0.5367\n",
      "Epoch 20/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.7240 - accuracy: 0.5671\n",
      "Epoch 21/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7300 - accuracy: 0.5725\n",
      "Epoch 22/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7589 - accuracy: 0.5206\n",
      "Epoch 23/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7388 - accuracy: 0.5321\n",
      "Epoch 24/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.5605\n",
      "Epoch 25/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.5314\n",
      "Epoch 26/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.7020 - accuracy: 0.5646\n",
      "Epoch 27/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7025 - accuracy: 0.5689\n",
      "Epoch 28/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.5658\n",
      "Epoch 29/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.6370\n",
      "Epoch 30/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6775 - accuracy: 0.5818\n",
      "Epoch 31/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7286 - accuracy: 0.5174\n",
      "Epoch 32/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7059 - accuracy: 0.5541\n",
      "Epoch 33/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.5799\n",
      "Epoch 34/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6992 - accuracy: 0.5919\n",
      "Epoch 35/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7253 - accuracy: 0.5109\n",
      "Epoch 36/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5782\n",
      "Epoch 37/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6998 - accuracy: 0.5573\n",
      "Epoch 38/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.6091\n",
      "Epoch 39/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.5831\n",
      "Epoch 40/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.5974\n",
      "Epoch 41/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7192 - accuracy: 0.5656\n",
      "Epoch 42/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6835 - accuracy: 0.5760\n",
      "Epoch 43/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.6186\n",
      "Epoch 44/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6744 - accuracy: 0.5960\n",
      "Epoch 45/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.6219\n",
      "Epoch 46/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7259 - accuracy: 0.5379\n",
      "Epoch 47/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6816 - accuracy: 0.5920\n",
      "Epoch 48/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5694\n",
      "Epoch 49/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.5840\n",
      "Epoch 50/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7184 - accuracy: 0.5606\n",
      "Epoch 51/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.5713\n",
      "Epoch 52/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.6103\n",
      "Epoch 53/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.5976\n",
      "Epoch 54/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.5702\n",
      "Epoch 55/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7216 - accuracy: 0.5261\n",
      "Epoch 56/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5802\n",
      "Epoch 57/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6762 - accuracy: 0.5455\n",
      "Epoch 58/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.5824\n",
      "Epoch 59/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6640 - accuracy: 0.6327\n",
      "Epoch 60/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5834\n",
      "Epoch 61/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5731\n",
      "Epoch 62/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.7348 - accuracy: 0.5141\n",
      "Epoch 63/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5866\n",
      "Epoch 64/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6716 - accuracy: 0.5760\n",
      "Epoch 65/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6755 - accuracy: 0.6187\n",
      "Epoch 66/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.6211\n",
      "Epoch 67/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.5762\n",
      "Epoch 68/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7100 - accuracy: 0.5654\n",
      "Epoch 69/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6949 - accuracy: 0.5363\n",
      "Epoch 70/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6710 - accuracy: 0.5762\n",
      "Epoch 71/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.6551\n",
      "Epoch 72/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5726\n",
      "Epoch 73/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.5655\n",
      "Epoch 74/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6663 - accuracy: 0.6248\n",
      "Epoch 75/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5838\n",
      "Epoch 76/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6161\n",
      "Epoch 77/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.6060\n",
      "Epoch 78/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.5903\n",
      "Epoch 79/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.5604\n",
      "Epoch 80/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5982\n",
      "Epoch 81/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7031 - accuracy: 0.5751\n",
      "Epoch 82/150\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.5707\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6657 - accuracy: 0.5866\n",
      "Epoch 84/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6663 - accuracy: 0.5894\n",
      "Epoch 85/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5698\n",
      "Epoch 86/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.6180\n",
      "Epoch 87/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5796\n",
      "Epoch 88/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6954 - accuracy: 0.5904\n",
      "Epoch 89/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.7048 - accuracy: 0.5666\n",
      "Epoch 90/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.5730\n",
      "Epoch 91/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.5919\n",
      "Epoch 92/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6792 - accuracy: 0.5986\n",
      "Epoch 93/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6646 - accuracy: 0.6483\n",
      "Epoch 94/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5754\n",
      "Epoch 95/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6688 - accuracy: 0.6178\n",
      "Epoch 96/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.7039 - accuracy: 0.5546\n",
      "Epoch 97/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.6074\n",
      "Epoch 98/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5677\n",
      "Epoch 99/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6079\n",
      "Epoch 100/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.7305 - accuracy: 0.5610\n",
      "Epoch 101/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6338\n",
      "Epoch 102/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.5922\n",
      "Epoch 103/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6607 - accuracy: 0.6430\n",
      "Epoch 104/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6612 - accuracy: 0.6156\n",
      "Epoch 105/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.7030 - accuracy: 0.5621\n",
      "Epoch 106/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6417 - accuracy: 0.6358\n",
      "Epoch 107/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.6275\n",
      "Epoch 108/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.6117\n",
      "Epoch 109/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6755 - accuracy: 0.5987\n",
      "Epoch 110/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6678 - accuracy: 0.6085\n",
      "Epoch 111/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6756 - accuracy: 0.5993\n",
      "Epoch 112/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.7144 - accuracy: 0.5809\n",
      "Epoch 113/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5480\n",
      "Epoch 114/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.6113\n",
      "Epoch 115/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5717\n",
      "Epoch 116/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6616 - accuracy: 0.6116\n",
      "Epoch 117/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6954 - accuracy: 0.5701\n",
      "Epoch 118/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 0.6011\n",
      "Epoch 119/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.7364 - accuracy: 0.5749\n",
      "Epoch 120/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6538 - accuracy: 0.5824\n",
      "Epoch 121/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.6256\n",
      "Epoch 122/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6998 - accuracy: 0.5993\n",
      "Epoch 123/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6347\n",
      "Epoch 124/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6778 - accuracy: 0.5556\n",
      "Epoch 125/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.5910\n",
      "Epoch 126/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5899\n",
      "Epoch 127/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.7139 - accuracy: 0.5706\n",
      "Epoch 128/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.7013 - accuracy: 0.5881\n",
      "Epoch 129/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.6635\n",
      "Epoch 130/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6386 - accuracy: 0.6628\n",
      "Epoch 131/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.5864\n",
      "Epoch 132/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.5892\n",
      "Epoch 133/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6143\n",
      "Epoch 134/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6389 - accuracy: 0.6309\n",
      "Epoch 135/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6754 - accuracy: 0.6242\n",
      "Epoch 136/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.6322\n",
      "Epoch 137/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6641 - accuracy: 0.6105\n",
      "Epoch 138/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6686 - accuracy: 0.5784\n",
      "Epoch 139/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6292\n",
      "Epoch 140/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7104 - accuracy: 0.5573\n",
      "Epoch 141/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6736 - accuracy: 0.5410\n",
      "Epoch 142/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5988\n",
      "Epoch 143/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.6020\n",
      "Epoch 144/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6656 - accuracy: 0.6125\n",
      "Epoch 145/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6442 - accuracy: 0.5990\n",
      "Epoch 146/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.7167 - accuracy: 0.5631\n",
      "Epoch 147/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6656 - accuracy: 0.6012\n",
      "Epoch 148/150\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5453\n",
      "Epoch 149/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6778 - accuracy: 0.5680\n",
      "Epoch 150/150\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.5920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x245b818d5e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_k=X[:,:-1]\n",
    "Y_k=X[:,-1]\n",
    "model.fit(X_k, Y_k, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6707 - accuracy: 0.5933\n",
      "Accuracy: 0.5933333039283752\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_k, Y_k)\n",
    "print('Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0008\n",
    "training_epochs = 2000\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_9:0' shape=(3, 300) dtype=float64>\n",
      "Output layer result: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Prediction result: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Error result: \n",
      " [[1. 0. 0. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 1. 1. 0.]]\n",
      "\n",
      "\n",
      "Epoch:  1  - Error:  42300.0\n",
      "Epoch:  2  - Error:  0.0\n",
      "\n",
      "Weights to the best accuracy: \n",
      " [[1508.0942492     0.            0.         1508.0942492     0.\n",
      "     0.            0.         1508.0942492  1508.0942492     0.\n",
      "     0.            0.         1508.0942492     0.            0.\n",
      "  1508.0942492     0.         1508.0942492  1508.0942492     0.\n",
      "  1508.0942492     0.            0.            0.            0.\n",
      "     0.            0.            0.            0.         1508.0942492\n",
      "  1508.0942492     0.            0.            0.            0.\n",
      "     0.            0.         1508.0942492     0.            0.\n",
      "  1508.0942492     0.         1508.0942492     0.            0.\n",
      "  1508.0942492  1508.0942492     0.            0.            0.\n",
      "     0.         1508.0942492     0.         1508.0942492     0.\n",
      "  1508.0942492  1508.0942492  1508.0942492     0.         1508.0942492\n",
      "  1508.0942492     0.            0.         1508.0942492  1508.0942492\n",
      "  1508.0942492     0.            0.         1508.0942492     0.\n",
      "  1508.0942492  1508.0942492  1508.0942492  1508.0942492  1508.0942492\n",
      "     0.         1508.0942492  1508.0942492  1508.0942492     0.\n",
      "     0.         1508.0942492     0.         1508.0942492  1508.0942492\n",
      "     0.            0.         1508.0942492  1508.0942492     0.\n",
      "  1508.0942492  1508.0942492     0.         1508.0942492     0.\n",
      "  1508.0942492     0.            0.            0.            0.\n",
      "     0.         1508.0942492  1508.0942492     0.         1508.0942492\n",
      "     0.            0.            0.            0.         1508.0942492\n",
      "     0.            0.         1508.0942492  1508.0942492     0.\n",
      "  1508.0942492  1508.0942492     0.         1508.0942492  1508.0942492\n",
      "     0.            0.            0.         1508.0942492  1508.0942492\n",
      "  1508.0942492     0.            0.            0.            0.\n",
      "     0.            0.            0.            0.            0.\n",
      "  1508.0942492  1508.0942492     0.         1508.0942492     0.\n",
      "     0.            0.            0.         1508.0942492  1508.0942492\n",
      "     0.            0.            0.         1508.0942492     0.\n",
      "  1508.0942492     0.            0.            0.         1508.0942492\n",
      "  1508.0942492     0.            0.         1508.0942492     0.\n",
      "     0.            0.         1508.0942492  1508.0942492     0.\n",
      "     0.            0.            0.         1508.0942492  1508.0942492\n",
      "     0.         1508.0942492  1508.0942492  1508.0942492  1508.0942492\n",
      "     0.         1508.0942492     0.            0.            0.\n",
      "     0.         1508.0942492  1508.0942492     0.         1508.0942492\n",
      "     0.         1508.0942492     0.         1508.0942492     0.\n",
      "     0.            0.         1508.0942492  1508.0942492  1508.0942492\n",
      "  1508.0942492     0.         1508.0942492     0.            0.\n",
      "  1508.0942492     0.         1508.0942492     0.         1508.0942492\n",
      "     0.         1508.0942492  1508.0942492  1508.0942492  1508.0942492\n",
      "  1508.0942492  1508.0942492     0.         1508.0942492  1508.0942492\n",
      "  1508.0942492  1508.0942492  1508.0942492  1508.0942492     0.\n",
      "     0.         1508.0942492     0.         1508.0942492     0.\n",
      "  1508.0942492     0.            0.         1508.0942492     0.\n",
      "  1508.0942492     0.         1508.0942492  1508.0942492     0.\n",
      "     0.         1508.0942492     0.         1508.0942492  1508.0942492\n",
      "     0.         1508.0942492     0.            0.            0.\n",
      "  1508.0942492     0.            0.         1508.0942492     0.\n",
      "     0.            0.            0.         1508.0942492  1508.0942492\n",
      "  1508.0942492     0.            0.            0.         1508.0942492\n",
      "  1508.0942492  1508.0942492  1508.0942492  1508.0942492     0.\n",
      "     0.            0.         1508.0942492  1508.0942492  1508.0942492\n",
      "  1508.0942492  1508.0942492     0.         1508.0942492  1508.0942492\n",
      "  1508.0942492     0.         1508.0942492     0.            0.\n",
      "     0.            0.            0.            0.            0.\n",
      "  1508.0942492  1508.0942492     0.         1508.0942492  1508.0942492\n",
      "  1508.0942492  1508.0942492     0.         1508.0942492     0.\n",
      "  1508.0942492     0.         1508.0942492  1508.0942492     0.        ]\n",
      " [1549.36344553    0.            0.         1549.36344553    0.\n",
      "     0.            0.         1549.36344553 1549.36344553    0.\n",
      "     0.            0.         1549.36344553    0.            0.\n",
      "  1549.36344553    0.         1549.36344553 1549.36344553    0.\n",
      "  1549.36344553    0.            0.            0.            0.\n",
      "     0.            0.            0.            0.         1549.36344553\n",
      "  1549.36344553    0.            0.            0.            0.\n",
      "     0.            0.         1549.36344553    0.            0.\n",
      "  1549.36344553    0.         1549.36344553    0.            0.\n",
      "  1549.36344553 1549.36344553    0.            0.            0.\n",
      "     0.         1549.36344553    0.         1549.36344553    0.\n",
      "  1549.36344553 1549.36344553 1549.36344553    0.         1549.36344553\n",
      "  1549.36344553    0.            0.         1549.36344553 1549.36344553\n",
      "  1549.36344553    0.            0.         1549.36344553    0.\n",
      "  1549.36344553 1549.36344553 1549.36344553 1549.36344553 1549.36344553\n",
      "     0.         1549.36344553 1549.36344553 1549.36344553    0.\n",
      "     0.         1549.36344553    0.         1549.36344553 1549.36344553\n",
      "     0.            0.         1549.36344553 1549.36344553    0.\n",
      "  1549.36344553 1549.36344553    0.         1549.36344553    0.\n",
      "  1549.36344553    0.            0.            0.            0.\n",
      "     0.         1549.36344553 1549.36344553    0.         1549.36344553\n",
      "     0.            0.            0.            0.         1549.36344553\n",
      "     0.            0.         1549.36344553 1549.36344553    0.\n",
      "  1549.36344553 1549.36344553    0.         1549.36344553 1549.36344553\n",
      "     0.            0.            0.         1549.36344553 1549.36344553\n",
      "  1549.36344553    0.            0.            0.            0.\n",
      "     0.            0.            0.            0.            0.\n",
      "  1549.36344553 1549.36344553    0.         1549.36344553    0.\n",
      "     0.            0.            0.         1549.36344553 1549.36344553\n",
      "     0.            0.            0.         1549.36344553    0.\n",
      "  1549.36344553    0.            0.            0.         1549.36344553\n",
      "  1549.36344553    0.            0.         1549.36344553    0.\n",
      "     0.            0.         1549.36344553 1549.36344553    0.\n",
      "     0.            0.            0.         1549.36344553 1549.36344553\n",
      "     0.         1549.36344553 1549.36344553 1549.36344553 1549.36344553\n",
      "     0.         1549.36344553    0.            0.            0.\n",
      "     0.         1549.36344553 1549.36344553    0.         1549.36344553\n",
      "     0.         1549.36344553    0.         1549.36344553    0.\n",
      "     0.            0.         1549.36344553 1549.36344553 1549.36344553\n",
      "  1549.36344553    0.         1549.36344553    0.            0.\n",
      "  1549.36344553    0.         1549.36344553    0.         1549.36344553\n",
      "     0.         1549.36344553 1549.36344553 1549.36344553 1549.36344553\n",
      "  1549.36344553 1549.36344553    0.         1549.36344553 1549.36344553\n",
      "  1549.36344553 1549.36344553 1549.36344553 1549.36344553    0.\n",
      "     0.         1549.36344553    0.         1549.36344553    0.\n",
      "  1549.36344553    0.            0.         1549.36344553    0.\n",
      "  1549.36344553    0.         1549.36344553 1549.36344553    0.\n",
      "     0.         1549.36344553    0.         1549.36344553 1549.36344553\n",
      "     0.         1549.36344553    0.            0.            0.\n",
      "  1549.36344553    0.            0.         1549.36344553    0.\n",
      "     0.            0.            0.         1549.36344553 1549.36344553\n",
      "  1549.36344553    0.            0.            0.         1549.36344553\n",
      "  1549.36344553 1549.36344553 1549.36344553 1549.36344553    0.\n",
      "     0.            0.         1549.36344553 1549.36344553 1549.36344553\n",
      "  1549.36344553 1549.36344553    0.         1549.36344553 1549.36344553\n",
      "  1549.36344553    0.         1549.36344553    0.            0.\n",
      "     0.            0.            0.            0.            0.\n",
      "  1549.36344553 1549.36344553    0.         1549.36344553 1549.36344553\n",
      "  1549.36344553 1549.36344553    0.         1549.36344553    0.\n",
      "  1549.36344553    0.         1549.36344553 1549.36344553    0.        ]\n",
      " [1487.17303387    0.            0.         1487.17303387    0.\n",
      "     0.            0.         1487.17303387 1487.17303387    0.\n",
      "     0.            0.         1487.17303387    0.            0.\n",
      "  1487.17303387    0.         1487.17303387 1487.17303387    0.\n",
      "  1487.17303387    0.            0.            0.            0.\n",
      "     0.            0.            0.            0.         1487.17303387\n",
      "  1487.17303387    0.            0.            0.            0.\n",
      "     0.            0.         1487.17303387    0.            0.\n",
      "  1487.17303387    0.         1487.17303387    0.            0.\n",
      "  1487.17303387 1487.17303387    0.            0.            0.\n",
      "     0.         1487.17303387    0.         1487.17303387    0.\n",
      "  1487.17303387 1487.17303387 1487.17303387    0.         1487.17303387\n",
      "  1487.17303387    0.            0.         1487.17303387 1487.17303387\n",
      "  1487.17303387    0.            0.         1487.17303387    0.\n",
      "  1487.17303387 1487.17303387 1487.17303387 1487.17303387 1487.17303387\n",
      "     0.         1487.17303387 1487.17303387 1487.17303387    0.\n",
      "     0.         1487.17303387    0.         1487.17303387 1487.17303387\n",
      "     0.            0.         1487.17303387 1487.17303387    0.\n",
      "  1487.17303387 1487.17303387    0.         1487.17303387    0.\n",
      "  1487.17303387    0.            0.            0.            0.\n",
      "     0.         1487.17303387 1487.17303387    0.         1487.17303387\n",
      "     0.            0.            0.            0.         1487.17303387\n",
      "     0.            0.         1487.17303387 1487.17303387    0.\n",
      "  1487.17303387 1487.17303387    0.         1487.17303387 1487.17303387\n",
      "     0.            0.            0.         1487.17303387 1487.17303387\n",
      "  1487.17303387    0.            0.            0.            0.\n",
      "     0.            0.            0.            0.            0.\n",
      "  1487.17303387 1487.17303387    0.         1487.17303387    0.\n",
      "     0.            0.            0.         1487.17303387 1487.17303387\n",
      "     0.            0.            0.         1487.17303387    0.\n",
      "  1487.17303387    0.            0.            0.         1487.17303387\n",
      "  1487.17303387    0.            0.         1487.17303387    0.\n",
      "     0.            0.         1487.17303387 1487.17303387    0.\n",
      "     0.            0.            0.         1487.17303387 1487.17303387\n",
      "     0.         1487.17303387 1487.17303387 1487.17303387 1487.17303387\n",
      "     0.         1487.17303387    0.            0.            0.\n",
      "     0.         1487.17303387 1487.17303387    0.         1487.17303387\n",
      "     0.         1487.17303387    0.         1487.17303387    0.\n",
      "     0.            0.         1487.17303387 1487.17303387 1487.17303387\n",
      "  1487.17303387    0.         1487.17303387    0.            0.\n",
      "  1487.17303387    0.         1487.17303387    0.         1487.17303387\n",
      "     0.         1487.17303387 1487.17303387 1487.17303387 1487.17303387\n",
      "  1487.17303387 1487.17303387    0.         1487.17303387 1487.17303387\n",
      "  1487.17303387 1487.17303387 1487.17303387 1487.17303387    0.\n",
      "     0.         1487.17303387    0.         1487.17303387    0.\n",
      "  1487.17303387    0.            0.         1487.17303387    0.\n",
      "  1487.17303387    0.         1487.17303387 1487.17303387    0.\n",
      "     0.         1487.17303387    0.         1487.17303387 1487.17303387\n",
      "     0.         1487.17303387    0.            0.            0.\n",
      "  1487.17303387    0.            0.         1487.17303387    0.\n",
      "     0.            0.            0.         1487.17303387 1487.17303387\n",
      "  1487.17303387    0.            0.            0.         1487.17303387\n",
      "  1487.17303387 1487.17303387 1487.17303387 1487.17303387    0.\n",
      "     0.            0.         1487.17303387 1487.17303387 1487.17303387\n",
      "  1487.17303387 1487.17303387    0.         1487.17303387 1487.17303387\n",
      "  1487.17303387    0.         1487.17303387    0.            0.\n",
      "     0.            0.            0.            0.            0.\n",
      "  1487.17303387 1487.17303387    0.         1487.17303387 1487.17303387\n",
      "  1487.17303387 1487.17303387    0.         1487.17303387    0.\n",
      "  1487.17303387    0.         1487.17303387 1487.17303387    0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def step_function(sum_value):\n",
    "    return tf.cast(tf.compat.v1.to_float(tf.compat.v1.math.greater_equal(sum_value, 1)), tf.float64)\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "weights = tf.Variable(tf.zeros([3,300], dtype = tf.compat.v1.float64))\n",
    "print(weights)\n",
    "\n",
    "output_layer = tf.matmul(X_k,weights)\n",
    "predictions = step_function(output_layer)\n",
    "error = tf.subtract(Y_k, predictions)\n",
    "delta = tf.matmul(X_k, error, transpose_a = True)\n",
    "learningRate = 0.1\n",
    "train = tf.compat.v1.assign(weights, tf.add(weights, tf.multiply(delta, learningRate)))\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "with tf.compat.v1.Session() as s:\n",
    "    s.run(init)\n",
    "    print('Output layer result: \\n', s.run(output_layer))\n",
    "    print('Prediction result: \\n', s.run(predictions))\n",
    "    print('Error result: \\n', s.run(error))\n",
    "    print('\\n')\n",
    "    for epoch in range(15):\n",
    "        train_error, _ = s.run([error, train])\n",
    "        train_error_sum = tf.reduce_sum(train_error)\n",
    "        print('Epoch: ', epoch+1, ' - Error: ', s.run(train_error_sum))\n",
    "        if train_error_sum.eval() == 0.0:\n",
    "            break; # learned and got 100% accuracy\n",
    "    print('\\nWeights to the best accuracy: \\n', s.run(weights))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
